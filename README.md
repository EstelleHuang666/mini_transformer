# Mini Transformer
This project is a realization of Transformer[1]. It is base on the Tensor2Tensor framwork[2] but simplifies many components. This mini Tensor2Tensor framework is suitable for the development of deep learning network in the laboratory level. It enables you to regard data preprocessing, model, layer as separate components and provides great flexibility to explore different network structure.


# Reference
[1] Vaswani, Ashish, et al. "Attention is all you need." Advances in neural information processing systems. 2017.
[2] Vaswani, Ashish, et al. "Tensor2tensor for neural machine translation." arXiv preprint arXiv:1803.07416 (2018).
